{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import math, copy\n",
    "from random import randint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "# from model_architectures import Encoder_RNN, Decoder_RNN\n",
    "from data_prep import prepareData, tensorsFromPair, prepareNonTrainDataForLanguagePair, load_cpickle_gc\n",
    "from misc import timeSince, load_cpickle_gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: PAD_token, 1: SOS_token, 2: EOS_token, 3:UNK_token}\n",
    "        self.n_words = 4  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "PAD_token = 0\n",
    "PAD_TOKEN = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "teacher_forcing_ratio = 1.0\n",
    "attn_model = 'dot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_idx_pairs = load_cpickle_gc(\"./iwslt-vi-eng/preprocessed_no_indices_pairs_train_tokenized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_lang = load_cpickle_gc(\"iwslt-vi-eng/preprocessed_no_elmo_vilang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_lang = load_cpickle_gc(\"iwslt-vi-eng/preprocessed_no_elmo_englang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_idx_pairs =  pickle.load(open(\"iwslt-vi-eng/preprocessed_no_indices_pairs_validation_tokenized\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_idx_pairs =  pickle.load(open(\"iwslt-vi-eng/preprocessed_no_indices_pairs_train_tokenized\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133317\n"
     ]
    }
   ],
   "source": [
    "print(len(train_idx_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LanguagePairDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sent_pairs): \n",
    "        # this is a list of sentences \n",
    "        self.sent_pairs_list = sent_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sent_pairs_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        sent1 = self.sent_pairs_list[key][0]\n",
    "        sent2 = self.sent_pairs_list[key][1]\n",
    "        return [sent1, sent2, len(sent1), len(sent2)]\n",
    "\n",
    "def language_pair_dataset_collate_function(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    sent1_list = []\n",
    "    sent1_length_list = []\n",
    "    sent2_list = []\n",
    "    sent2_length_list = []\n",
    "    # padding\n",
    "    # NOW PAD WITH THE MAXIMUM LENGTH OF THE FIRST and second batches \n",
    "    max_length_1 = max([len(x[0]) for x in batch])\n",
    "    max_length_2 = max([len(x[1]) for x in batch])\n",
    "    for datum in batch:\n",
    "        padded_vec_1 = np.pad(np.array(datum[0]).T.squeeze(), pad_width=((0,max_length_1-len(datum[0]))), \n",
    "                                mode=\"constant\", constant_values=PAD_token)\n",
    "        padded_vec_2 = np.pad(np.array(datum[1]).T.squeeze(), pad_width=((0,max_length_2-len(datum[1]))), \n",
    "                                mode=\"constant\", constant_values=PAD_token)\n",
    "        sent1_list.append(padded_vec_1)\n",
    "        sent2_list.append(padded_vec_2)\n",
    "        sent1_length_list.append(len(datum[0]))\n",
    "        sent2_length_list.append(len(datum[1]))\n",
    "    return [torch.from_numpy(np.array(sent1_list)), torch.cuda.LongTensor(sent1_length_list), \n",
    "            torch.from_numpy(np.array(sent2_list)), torch.cuda.LongTensor(sent2_length_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = LanguagePairDataset(train_idx_pairs)\n",
    "# is there anything in the train_idx_pairs that is only 0s right noww instea dof padding. \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           collate_fn=language_pair_dataset_collate_function,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder_RNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(Decoder_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size).cuda()\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size).cuda()\n",
    "        self.out = nn.Linear(hidden_size, output_size).cuda()\n",
    "        self.softmax = nn.LogSoftmax(dim=1).cuda()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embed = self.embedding(input).view(1, 1, -1)\n",
    "        embed = F.relu(embed).cuda()\n",
    "        output, hidden = self.gru(embed, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SupEncoder(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    A super class of Encoder that learns embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, src_embed):\n",
    "        super(SupEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.src_embed = src_embed \n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \"Take in and process masked src sequences.\"\n",
    "        a = self.encode(src, src_mask)\n",
    "#         a = tf.math.reduce_mean(a, axis=1,keepdims=True)\n",
    "\n",
    "        a = a[:,0,:]\n",
    "        a = a.unsqueeze(1)\n",
    "        a = a.cuda()\n",
    "#         pdb.set_trace()\n",
    "#         print(np.shape(a))\n",
    "        return a\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "#     module = module.cpu()\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    \n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        x = x.cuda()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        features = features\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.cuda()\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return (self.a_2 * (x - mean) / (std + self.eps) + self.b_2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        x = x.cuda()\n",
    "        return (x + self.dropout(sublayer(self.norm(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = x.cuda()\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = mask.cuda()\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        query = query.cuda()\n",
    "        key = key.cuda()\n",
    "        value = value.cuda()\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.cuda()\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        \n",
    "        return self.linears[-1](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff).cuda()\n",
    "        self.w_2 = nn.Linear(d_ff, d_model).cuda()\n",
    "        self.dropout = nn.Dropout(dropout).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.cuda()\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x)).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model).cuda()\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is the weights here\n",
    "        x = x.cuda()\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).cuda()\n",
    "        position = torch.arange(0., max_len).unsqueeze(1).cuda()\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        div_term = div_term.cuda()\n",
    "#         pdb.set_trace()\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         pdb.set_trace()\n",
    "        x = x.cuda()\n",
    "        x = x + Variable(self.pe[:, :x.size(1)],requires_grad=False)\n",
    "\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length, count):\n",
    "#     encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    err_real = 0\n",
    "    loss = 0\n",
    "#     encoder_outputs = torch.zeros(max_length, decoder.hidden_size, device=device)\n",
    "\n",
    "    # iterate GRU over words --> final hidden state is representation of source sentence. \n",
    "    for ei in range(input_length):\n",
    "#         encoder_output = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_output = encoder(input_tensor[ei],None)\n",
    "#         encoder_outputs[ei] = encoder_output[0,0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_output\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(1, target_length-1):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "#             err_real += loss.data[0]\n",
    "#             err_real += loss.item()\n",
    "            count += 1\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(1, target_length-1):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "#             err_real += loss.data[0]\n",
    "#             err_real += loss.item()\n",
    "            count += 1\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "                \n",
    "    if type(loss) != torch.Tensor:\n",
    "#         pdb.set_trace()\n",
    "        loss = torch.Tensor(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder,n_epochs, validation_pairs, pairs, lang1, lang2, max_length, max_length_generation, title, print_every=5000, plot_every=5000, learning_rate=3e-4, search=\"beam\"):\n",
    "    \"\"\"\n",
    "    lang1 is the Lang o|bject for language 1 \n",
    "    Lang2 is the Lang object for language 2\n",
    "    n_iters is the number of training pairs per epoch you want to train on\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    training_pairs = pairs\n",
    "    n_iters = len(pairs)\n",
    "    plot_losses, val_losses = [], []\n",
    "    val_losses = [] \n",
    "    count, print_loss_total, plot_loss_total, val_loss_total, plot_val_loss = 0, 0, 0, 0, 0 \n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss(ignore_index=PAD_token)\n",
    "    plot_loss =[]\n",
    "    val_loss = []\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        plot_loss =[]\n",
    "        val_loss = []\n",
    "        # framing it as a categorical loss function. \n",
    "        for iter in range(1, n_iters + 1):\n",
    "            training_pair = training_pairs[iter - 1] \n",
    "            input_tensor = training_pair[0]\n",
    "            target_tensor = training_pair[1]\n",
    "            input_length = input_tensor.size(0)\n",
    "            if target_tensor.size(0) < 3:\n",
    "                continue\n",
    "            loss_value, count = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length, count)\n",
    "            print_loss_total += loss_value \n",
    "            plot_loss_total += loss_value\n",
    "            \n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / count\n",
    "                count = 0\n",
    "                print_loss_total = 0\n",
    "                print('TRAIN SCORE %s (%d %d%%) %.4f' % (timeSince(start, iter / n_epochs),\n",
    "                                             iter, iter / n_epochs * 100, print_loss_avg))\n",
    "                plot_loss.append(print_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                with torch.no_grad():\n",
    "                    v_loss = test_model(encoder, decoder, search, validation_pairs, lang2, max_length=max_length_generation)\n",
    "                # returns bleu score\n",
    "                print(\"VALIDATION BLEU SCORE: \"+str(v_loss))\n",
    "                val_loss.append(v_loss)\n",
    "                save_model(encoder,decoder, title)\n",
    "        plot_losses.append(plot_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        save_model(encoder,decoder, title)\n",
    "        make_graph(encoder, decoder, val_losses, plot_losses, title)\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(encoder, decoder, title):\n",
    "    link = title.replace(\" \", \"\")\n",
    "    torch.save(encoder.state_dict(), \"output/\"+link + \"encodermodel_states\")\n",
    "    torch.save(decoder.state_dict(), \"output/\"+link + \"decodermodel_states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_graph(encoder, decoder, val_accs, train_accs, title):\n",
    "    print(\"SAVE\")\n",
    "    val_accs = np.array(val_accs) # this is the BLEU score. \n",
    "    max_val = val_accs.max() \n",
    "    train_accs = np.array(train_accs)\n",
    "    link = title.replace(\" \", \"\")\n",
    "    pickle.dump(val_accs, open(\"output/\"+link + \"val_accuracies\", \"wb\"))\n",
    "    pickle.dump(train_accs, open(\"output/\"+link + \"train_accuracies\", \"wb\"))\n",
    "    pickle.dump(max_val, open(\"output/\"+link + \"maxvalaccis\"+str(max_val), \"wb\"))\n",
    "    # this is when you want to overlay\n",
    "    num_in_epoch = np.shape(train_accs)[1]\n",
    "    num_epochs = np.shape(train_accs)[0]\n",
    "    x_vals_train = np.arange(0, num_epochs, 1.0/float(num_in_epoch))\n",
    "    num_in_epoch = np.shape(val_accs)[1]\n",
    "    num_epochs = np.shape(val_accs)[0]\n",
    "    x_vals_val = np.arange(0, num_epochs, 1.0/float(num_in_epoch))\n",
    "    fig = plt.figure()\n",
    "    plt.title(title)\n",
    "    # plot the title of this data. \n",
    "    plt.plot(x_vals_train, train_accs.flatten(), label=\"Training Loss (NLLoss)\")\n",
    "    plt.plot(x_vals_val, val_accs.flatten(), label=\"Validation Accuracy (BLEU score)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.ylabel(\"Accuracy of Model\")\n",
    "    plt.xlabel(\"Epochs (Batch Size 32)\")\n",
    "    plt.ylim(0, 50) # for loss\n",
    "    plt.xlim(0, num_epochs)\n",
    "    plt.yticks([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    plt.xticks(np.arange(num_epochs + 1))\n",
    "    fig.savefig(\"output/\"+link+\"graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "# number of duplicate layers in encoder\n",
    "N = 1\n",
    "# number of heads\n",
    "h=8\n",
    "dropout=0.1\n",
    "\"Helper: Construct a model from hyperparameters.\"\n",
    "attn = MultiHeadedAttention(h, hidden_size).cuda()\n",
    "ff = PositionwiseFeedForward(hidden_size,input_lang.n_words, dropout).cuda()\n",
    "position = PositionalEncoding(hidden_size, dropout).cuda()\n",
    "src_embed = nn.Sequential(Embeddings(hidden_size, input_lang.n_words), position).cuda()\n",
    "encoder1 = SupEncoder(Encoder(EncoderLayer(hidden_size, attn, ff, dropout), N),src_embed).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "def calculate_bleu(predictions, labels):\n",
    "    \"\"\"\n",
    "    Only pass a list of strings \n",
    "    \"\"\"\n",
    "    # tthis is ony with n_gram = 4\n",
    "\n",
    "    bleu = sacrebleu.raw_corpus_bleu(predictions, [labels], .01).score\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(encoder, decoder, search, test_pairs, lang2, max_length=None):\n",
    "    # for test, you only need the lang1 words to be tokenized,\n",
    "    # lang2 words is the true labels\n",
    "    encoder_inputs = [pair[0] for pair in test_pairs]\n",
    "    true_labels = [pair[1] for pair in test_pairs]\n",
    "    translated_predictions = []\n",
    "    for i in range(len(encoder_inputs)):\n",
    "        e_input = encoder_inputs[i]\n",
    "        if max_length is None:\n",
    "            max_length = len(e_input)\n",
    "        decoded_words = generate_translation(encoder, decoder, e_input, max_length, lang2, search=search)\n",
    "        translated_predictions.append(\" \".join(decoded_words))\n",
    "    rand = randint(0, 1)\n",
    "    print(translated_predictions[rand])\n",
    "    print(true_labels[rand])\n",
    "    bleurg = calculate_bleu(translated_predictions, true_labels)\n",
    "    return bleurg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_translation(encoder, decoder, sentence, max_length, target_lang, search=\"greedy\", k = None):\n",
    "    \"\"\" \n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @returns decoded_words: a list of words in target language\n",
    "    \"\"\"    \n",
    "    with torch.no_grad():\n",
    "        input_tensor = sentence\n",
    "        input_length = sentence.size()[0]\n",
    "        \n",
    "        # encode the source sentence\n",
    "        \n",
    "        encoder_output = encoder(input_tensor.view(1, -1),torch.tensor([input_length]))\n",
    "        # start decoding\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        decoder_hidden = encoder_output\n",
    "        decoded_words = []\n",
    "        \n",
    "        if search == 'beam':\n",
    "            if k == None:\n",
    "                k = 5 # since k = 2 preforms badly\n",
    "            decoded_words = beam_search(decoder, decoder_input, decoder_hidden, max_length, k, target_lang)  \n",
    "        elif search == 'greedy':\n",
    "            decoded_words = greedy_search(decoder, decoder_input, decoder_hidden, max_length)\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beam_search(decoder, decoder_input, hidden, max_length, k, target_lang):\n",
    "    \n",
    "    candidates = [(decoder_input, 0, hidden)]\n",
    "    potential_candidates = []\n",
    "    completed_translations = []\n",
    "\n",
    "    # put a cap on the length of generated sentences\n",
    "    for m in range(max_length):\n",
    "        for c in candidates:\n",
    "            # unpack the tuple\n",
    "            c_sequence = c[0]\n",
    "            c_score = c[1]\n",
    "            c_hidden = c[2]\n",
    "            # EOS token\n",
    "            if c_sequence[-1] == EOS_token:\n",
    "                completed_translations.append((c_sequence, c_score))\n",
    "                k = k - 1\n",
    "            else:\n",
    "                next_word_probs, hidden = decoder(c_sequence[-1], c_hidden)\n",
    "                # in the worst-case, one sequence will have the highest k probabilities\n",
    "                # so to save computation, only grab the k highest_probability from each candidate sequence\n",
    "                top_probs, top_idx = torch.topk(next_word_probs, k)\n",
    "                for i in range(len(top_probs[0])):\n",
    "                    word = torch.from_numpy(np.array([top_idx[0][i]]).reshape(1, 1)).to(device)\n",
    "                    new_score = c_score + top_probs[0][i]\n",
    "                    potential_candidates.append((torch.cat((c_sequence, word)).to(device), new_score, c_hidden))\n",
    "\n",
    "        candidates = sorted(potential_candidates, key= lambda x: x[1])[0:k] \n",
    "        potential_candidates = []\n",
    "\n",
    "    completed = completed_translations + candidates\n",
    "    completed = sorted(completed, key= lambda x: x[1], reverse=True)[0] \n",
    "    #it's quite weird that it's not learning  what to do without the. . . \n",
    "    final_translation = []\n",
    "    for x in completed[0]:\n",
    "        final_translation.append(target_lang.index2word[x.squeeze().item()])\n",
    "    return final_translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "decoder1 = Decoder_RNN(target_lang.n_words,hidden_size).cuda()\n",
    "args = {\n",
    "    'n_epochs': 10,\n",
    "    'learning_rate': 0.001,\n",
    "    'search': 'beam',\n",
    "    'encoder': encoder1,\n",
    "    'decoder': decoder1,\n",
    "    'lang1': input_lang, \n",
    "    'lang2': target_lang,\n",
    "    \"pairs\":train_idx_pairs, \n",
    "    \"validation_pairs\": val_idx_pairs[:200], \n",
    "    \"title\": \"Training Curve for Basic Self Encoder With LR = 0.0001\",\n",
    "    \"max_length\": 100,\n",
    "    \"max_length_generation\": 20, \n",
    "    \"plot_every\": 500, \n",
    "    \"print_every\": 500\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "We follow https://arxiv.org/pdf/1406.1078.pdf \n",
    "and use the Adadelta optimizer\n",
    "\n",
    "\"\"\"\n",
    "print(BATCH_SIZE)\n",
    "\n",
    "trainIters(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
